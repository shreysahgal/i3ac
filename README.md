# Exploration with Inverse Dynamics-Aware Intrinsic Curiosity

<img src="https://github.com/shreysahgal/i3ac/blob/main/MARIO.png?raw=true" width="100" height="100">

Abstract: Exploratory behavior seems to be intrinsically rewarded in humans and crucial for our cognitive development. Moreover, in many real-world scenarios, extrinsic rewards for both humans and reinforcement learning (RL) agents in different environments are incredibly sparse or nonexistent altogether. In this paper, we expand on recent literature that aims to endow reinforcement learning agents with intrinsic curiosity with the goal of allowing the agent to explore and better understand its environment. We present I3AC: Investigative Inverse-aware Intrinsic Autonomous Curiosity, a framework which allows the agent to learn the inverse dynamics of its environment and select actions which will maximize learning progress, leading to exploratory behavior. We show experimental results for I3AC with an agent that learns to play the Super Mario Bros. video game. We analyze these results and show that I3AC is a reasonable proof-of-concept for implementing curiosity-based reinforcement learning methods in video game environments.
